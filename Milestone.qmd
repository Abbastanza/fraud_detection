---
title: "Vorhersage (Klassifikation) betrügerischer Kontotransationen"
subtitle: "Solution Engineering in R"
author: "Daniel Borsos, Valerie Högerle, Michaela Hubweber, Florian Ye"
date: today
embed-resources: true
format:
  revealjs:
    scrollable: true
    smaller: true
    theme: solarized ##https://quarto.org/docs/presentations/revealjs/themes.html
    slide-level: 3
fig-align: center
execute: 
  warning: false
---



# Milestone 1 


## Zielsetzung des Projekts (qualitativ und quantitative Ziele)
### Qualitative Ziele: {.scrollable}
- Entwicklung eines robusten Klassifikationsmodells: Entwickeln eines Modells, das effektiv zwischen betrügerischen und legitimen Transaktionen unterscheiden kann, unter besonderer Berücksichtigung des stark inbalanced Datensatzes.
- Erkennung von Mustern und Anomalien: Identifizierung spezifischer Muster oder Anomalien in den Daten, die auf betrügerische Aktivitäten hindeuten könnten.
- Nutzbarkeit und Zugänglichkeit: Erstellung einer benutzerfreundlichen Shiny-Anwendung, die es Endnutzern ermöglicht, Vorhersagen einfach zu generieren und die Ergebnisse intuitiv zu verstehen.

### Quantitative Ziele: {.scrollable}
- ROC AUC-Wert: Erzielen eines ROC AUC-Wertes von mindestens 0.90, was auf eine ausgezeichnete Trennfähigkeit des Modells zwischen betrügerischen und legitimen Transaktionen hinweist.
- Hoher Recall für betrügerische Transaktionen: Streben nach einem Recall-Wert von über 90% bei betrügerischen Transaktionen, um sicherzustellen, dass die meisten tatsächlichen Betrugsfälle korrekt erkannt werden. Dies ist besonders wichtig, da das Übersehen von Betrug schwerwiegendere Konsequenzen haben kann als falsche Alarme.
- Ausgeglichener F1-Score für betrügerische Transaktionen: Ziel ist ein F1-Score von über 85% für die Klasse der betrügerischen Transaktionen, was ein gutes Gleichgewicht zwischen Präzision und Recall darstellt, wobei der Schwerpunkt auf dem Recall liegt.
- Schnelle Antwortzeiten der Shiny-Anwendung: Die Shiny-Anwendung sollte in der Lage sein, innerhalb weniger Sekunden Vorhersagen zu liefern, um effektive Echtzeitanwendungen zu ermöglichen.

## Beschreibung der Datengrundlage (Refenzdatensatz) 

Die Grundlage des Kaggle-Datensatzes "Fraudulent Transactions Prediction" besteht aus Transaktionsdaten, die für die Erkennung von Betrug im Online-Zahlungsverkehr verwendet werden. Der Datensatz enthält verschiedene Attribute wie "step", "type", "amount", "oldbalanceOrg", "newbalanceOrig", "nameDest", "oldbalanceDest", "newbalanceDest", "isFraud" und "isFlaggedFraud". Allerdings sind die Balance-Daten ("oldbalanceOrg", "newbalanceOrig", "oldbalanceDest", "newbalanceDest") nicht immer vollständig, da viele dieser Werte 0 sind.

Die Zielvariable "isFraud" ist außerdem unbalanciert, da 99.87% der Transaktionen nicht betrügerisch sind. Zudem scheint es keine signifikanten Korrelationen zwischen den Variablen zu geben, mit Ausnahme der Balance-Variablen, die viele Null-Werte enthalten und damit korrelieren .

Die Attribute im Überblick:

step: Zeiteinheit, wobei ein Schritt einer Stunde entspricht.
type: Art der Online-Transaktion, z. B. "CASH_OUT", "PAYMENT", "CASH_IN", "TRANSFER" oder "DEBIT".
amount: Betrag der Transaktion.
nameOrig: ID des Ursprungs-Kontos.
oldbalanceOrg: Anfangsguthaben des Ursprungs-Kontos.
newbalanceOrig: Guthaben des Ursprungs-Kontos nach der Transaktion.
nameDest: ID des Ziel-Kontos.
oldbalanceDest: Anfangsguthaben des Ziel-Kontos.
newbalanceDest: Guthaben des Ziel-Kontos nach der Transaktion.
isFraud: Kennzeichnet, ob es sich um einen Betrugsfall handelt oder nicht.
isFlaggedFraud: Kennzeichnet, ob die Transaktion als möglicher Betrugsfall markiert wurde.

## Projektorganisation und Aufgabenteilung [4 Punkte] Valerie
## Plan für die Ausarbeitung des Projekts (Workflow), Backlog 

### Projektplan und Workflow {.scrollable}

Der Backlog des Projekts befindet sich im zugehörigen [Repository](https://github.com/users/Abbastanza/projects/3) und enthält die unten aufgeführten Aufgaben:

::: {layout-ncol=2}

![Backlog](img/kanban.png)


![Timetable](img/workflow.png)

:::


1. **Datenexploration und -vorbereitung**
   - Datenimport und -exploration
   - Behandlung von fehlenden oder doppelten Werten
   - Feature Engineering und Transformation
   
2. **Modellentwicklung**
   - Aufteilung der Daten in Trainings- und Testdaten
      - Behandlung des Klassenungleichgewichts durch Sampling? 
   - Anwendung verschiedener Klassifikationsalgorithmen
      - Behandlung des Klassenungleichgewichts durch Wahl geeigneter Verfahren, die mit unbalancierten Daten umgehen können und/oder Gewichtung erlauben
   - Hyperparameter-Optimierung und Modellbewertung

3. **Modellvalidierung und -interpretation**
   - Evaluation der Modelle anhand der festgelegten quantitativen Ziele, z.B. ROC AUC, Recall, F1-Score
      - Behandlung des Klassenungleichgewichts durch Wahl geeigneter Metriken
   - Interpretation der Modellergebnisse und Identifikation/Interpretation wichtiger Features
   
4. **Entwicklung der Shiny-Anwendung:**
   - Implementierung einer benutzerfreundlichen Shiny-Anwendung
   - Integration des entwickelten Modells zur Generierung von Vorhersagen
   - Optimierung der Antwortzeiten für Echtzeitanwendungen

5. **Dokumentation und Präsentation**
   - Erstellung von Dokumentationen und Präsentationen
   - Vorbereitung für die Abschlusspräsentation und -abgabe

## Fragen? Anmerkungen? Diskussion? 

